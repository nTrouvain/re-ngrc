
\section{Introduction}

Reservoir Computing (RC) is a machine learning paradigm where
untrained recurrent neural networks called \textit{reservoirs} encode
temporal information within a high dimensional space.
A single layer of neuron, called the \textit{readout},
is then trained to decode this temporal embedding in order
to solve various tasks, from choatic timeseries prediction to pattern recognition.
\citet{gauthier2021next} propose a novel formulation of this paradigm under
the scope of dynamical system and autoregressive machines.
The reservoir might be seen as a Non-linear Vector AutoRegressive machine (NVAR),
combining lagged values of a multivariate timeseries
and non-linear recombinations of these values to predict next values. The
authors claim that this new RC formalism display similar capabilities to those
of its recurrent neural-networks powered counterpart. They also use this formalism
to bridge RC theoretical background and dynamical system theory.
In this report, we replicated all the experiments performed by \citet{gauthier2021next} 
in their paper. We also briefly describe our proposed reusable implementation
of the NVAR within the \textit{reservoirpy} RC library \supercite{trouvain2020}.
